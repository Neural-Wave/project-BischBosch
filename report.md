# Root Cause Analysis of Part Failures Using Causal Graph Discovery

## Objective
This project aims to identify the root causes of part failures by modeling causal relationships among measurements collected at multiple production stations. The significance of this analysis lies in its potential to improve production quality, reduce downtime, and enhance operational efficiency. By understanding the causal factors of failures, we can provide actionable insights for production adjustments and preemptively address the conditions that lead to part failure.

## Approach
Dataset and Preprocessing

The dataset comprises 2,500 instances of successful parts and 2,500 instances of failed parts, with measurements taken at five sequential stations. Causal dependencies in this multi-station setup are assumed to flow unidirectionally, where measurements at an earlier station can influence those at subsequent stations but not vice versa.

PC Algorithm (Peter and Clark):
The PC algorithm was used initially to identify dependencies by testing conditional independencies among variables. This algorithm is efficient in building undirected graphs, serving as a base model for comparison.

Fast Causal Inference (FCI) Algorithm:
The FCI algorithm from the causal-learn library generated a Partial Ancestral Graph (PAG), revealing dependencies with potential latent variables or hidden confounders. The FCI algorithm is useful in providing a robust conditional independence structure, incorporating both directed and undirected edges.

Linear Non-Gaussian Acyclic Model (LiNGAM):
The LiNGAM algorithm was chosen to address directional dependencies, particularly where data exhibited non-Gaussian characteristics. LiNGAM's linear assumptions provided an alternative directed graph and offered another perspective on dependency structure.

DAG-GNN (Graph Neural Network):
DAG-GNN provided a neural network-based approach, capable of modeling more complex structures directly from the adjacency matrix. The binary adjacency matrix generated by DAG-GNN allowed us to explore causal relationships in a structured and flexible manner, particularly useful for capturing nuanced causal paths.

## Graph Tools and Libraries
The project made extensive use of:
- networkx for handling directed graphs
- gCastle, causal-learn, and CausalDiscoveryToolbox for implementing the PC, FCI, and LiNGAM algorithm, and
- NumPy for data manipulation and adjacency matrix operations.

## Results
Key Findings

Analysis of the causal graph highlighted that measurements at Station 1 had the most significant influence on failure outcomes at downstream stations. The root cause analysis revealed that several early-stage measurements exhibited strong predictive power over failure, often preceding variations observed at subsequent stations.
Visualization and Metrics
The finalized causal adjacency matrix displayed distinct clusters of measurements with high influence on the failure node. These measurements consistently showed paths to failure, with key metrics indicating a correlation between early-stage measurements and downstream part outcomes. Figure 1 below (insert as placeholder) demonstrates an adjacency heatmap showcasing these relationships, visually emphasizing key influencers.
Interpretations
These findings suggest that early interventions at Station 1 could mitigate potential downstream issues, helping preemptively address factors linked to failure. The causal ranking of nodes further enabled prioritization of specific measurements for targeted process improvements.

Challenges

- Handling Undirected Edges in the PAG:
The FCI algorithm produced several undirected edges in the initial PAG output. To convert this to a fully directed acyclic graph suitable for causal analysis, assumptions were required. These were informed by domain knowledge and tested for statistical significance.

- Complexity of Root Cause Quantification:
Quantifying influence strength for root cause ranking presented additional complexity. This was managed by tracing influence paths and leveraging graph traversal techniques to isolate primary causal factors.
Balancing Model Complexity with Interpretability:
While the GNN model enabled nuanced analysis, interpretability remained a priority. Simplifying the model while maintaining robustness was a balancing act, achieved by focusing on direct influence paths and ranking root causes accordingly.